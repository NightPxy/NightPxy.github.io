---
layout: post
title:  "机器学习-开篇"
date:   2019-10-08 13:31:01 +0800
categories: jvm
tag: [ml]
---

* content
{:toc}


# 什么是机器学习

讨论机器学习之前，首先讨论下什么是人类学习  
人类是怎么学习的呢？看见朝霞，就会预测今天会下雨，看见晚霞就会预测明天是一个好天气  
这里涉及到归纳推理的应用  
从普遍性的下雨之前会看见朝霞，好天气之前会看到晚霞从而归纳出`朝霞=>下雨 晚霞=>晴天`  
这里的核心是,其实是`经验`两个字,也就是人类学习,也是通过经验而来  

机器学习,就是机器,通过模仿人类学习的方式进行学习,从而不断改善自身的一门学科  
也就是通过`学习`的手段,利用`经验`来改善系统自身性能.

而在机器学习中
* `经验`通常以数据的方式存在  
* `学习`的本质是学习算法(从数据中产生模型的算法)   
所以机器学习,就是调制产生学习算法,再把经验数据提供给它,它就能从这些经验数据根据学习算法产生一个模型,在面对一个新情况时,它就能从这个模型中产生相应的判断  

# 基本术语  

## 基本描述  

一组经验数据的记录集合,称之为`数据集`  
其中每条记录的描述,称之为`样本`或`示例`  
而反映关于事件或对象在某方面的表现或性质的事项,称为`属性`或`特征`  
每个属性上的取值,称之为`属性值`,而整个属性与属性值张成的空间,称之为`属性空间`,`样本空间`或`输入空间`，而在这个属性空间,每一个`样本`最终都会成为这个`属性空间`中的一个点,这个点称为`特征向量`(空间中的每个点称为特征向量)  

举例而论  
假设收集了一组西瓜的数据 `(色泽=青绿,敲声=浊响),(色泽=乌黑,敲声=沉闷),(色泽=浅白,敲声=清脆)`,这一组西瓜的数据,称之为`数据集`, 其中的每一条记录,称之为为一条`样本`  
在这些样本中,分别从描述了西瓜`色泽`,`根蒂`和`敲声`三个属性,称之为`属性`或`特征`  
将这三个特征,描述为了一个三维坐标系,这就是西瓜的`属性空间`,每一个西瓜最终都会成为这个坐标系中一个点，则称每一个西瓜在这个坐标系中的点为`特征向量`  

## 训练与测试集  

## 训练分类  

* `分类` 
如果欲预测的是离散值,则此类学习任务称之为`分类`  
其中如果只涉及两个分类的学习(诸如`是&否`),称之为`二分类`,通常称其中一个为`正类`,另一个`反类`  
涉及多个分类的学习,则称之为`多分类`  
* `回归`  
如果欲预测的是连续值,则此类学习称之为`回归`  
* `聚类`  
如果欲预测的不再是值,而是将训练集中的西瓜分为多个组,则称此类学习称之为`聚类`,其中每个组称之为`簇`,例如`深色瓜,浅色瓜,本地瓜,外地瓜,成熟瓜,半熟瓜`等等  
聚类学习有助于了解数据内在规律,为更为深入的分析数据建立基础,需要特别说明的是,聚类学习大多是无监督学习,即训练集通常不带有标记信息,事先也不知道可能的`簇`  

根据训练集是否带有标记数据,可以将学习任务大体分为两大类  
* 训练集已提前带有数据标记的,称之为`有监督学习`,代表诸如 `分类`,`回归`等等  
*  训练集没有任何数据标记的,称之为`无监督学习`,代表诸如`聚类`  

## 模型分类  

* 线性模型  
* 决策树  
* 神经网络  
* 支持向量机  
* 贝叶斯分类  
* 集成学习  

# 模型的评估与选择  

## 性能度量  

模型的`性能度量`并不是程序普遍意义的性能指标.它是指对学习器的泛化性能进行评估,简单来说就是评估模型是好与坏  

性能评估包含两个方法  
* 有效可行的实验估计方法  
* 衡量模型泛化能力的评价标准  

`性能度量`反映了任务需求  
在对比不同的性能度量往往会导致不同的评估结果,这意味着模型的好坏是相对的,什么样的模型是好的,不仅取决于算法和数据,也决定于任务需求

### 分类学习  

在分类学习中,用`错误率`和`精度`来评估模型  
`分类错误的样本数/总样本数`的比例,称之为`错误率`,相应的`1-错误率`,称之为`精度`  
一般来说,将这种`错误率`(与真实情况的差异),我们称之为`误差`  

`误差`我们总希望越小越好,但如果`精度`100%,是不是就是最好的模型呢?  
答案是不见得,事实上,`精度`100%往往表现的更差  
原因就在于`过拟合`的情况  

实际上,我们期望的是一个对所有样本都适用的情况,也就是`适用于所有潜在样本的普遍规律`  
但是,当学习器把训练样本学习的太好,可能会将训练样本的一些本身特点都学习进来,这就会再泛化情况下表现的非常差,这种情况,就称为`过拟合`  
与之对应的就是`欠拟合`,也就是学习器的学习特点不足  

举例而论,将夏天的各种树叶都放入学习中,如果刚好都选择了有锯齿的树叶, 有可能会得到一个结论`没有锯齿=>不是树叶`,但事实上树叶可能 没有锯齿的.  反之`绿色=>树叶`,有黄色,红色的.这就是`欠拟合`  


### 查准率与查全率  

以`西瓜`挑选出好西瓜为例,`错误率`或者`精度`可以描述有多少西瓜被判别错误,但`错误率`或者`精度`无法描述,挑出来的部分有多少是好西瓜(`查准率`),也无法描述有多少好西瓜被挑出(`查全率`)  

很多时候,`查准率`与`查全率`都是两个相当重要的指标  

一个二分类的混淆矩阵如下  

|真实情况|正例|反例|
|---|---|--|
|正例|TP(真正例)|FN(假反例)|
|假例|FP(假正例)|TN(真反例)|

很明显 `总集合=TP+FP+FN+TN`,而`查准率`与`查全率`说的是  

```
查准率=真正例/真正例+假真例 P=TP/(TP+FP)
简单来说,查准率就是回答准确是的问题

查全率=真正例/真正例+假反例 R=TP/(TP+FN)
简单来说,查准率就是回答准确不是的问题
```
可以继续推理出  
* 假真例越少,则查准率越高  
* 假反例越少,则查全率越高  
* 提高查准率,可以简单的提高判定标准,但这也代表着查全率会相应变低,因为更多的临界疑似会被判定假反,反之亦然,一个很简单的推论是,保证100%的查全率是最简单的,因为100%选择即可,但此时查准率也是最低的  
* 查准率与查全率,可以达到理论上的双高,但这代表分类无比精确,但这种无比的精确本身就可能是过拟合导致的问题,所以在实际的模型中,查准率与查全率往往是一对矛盾度量,具体选择往往取决于任务本身  

比如健康监测,可能更加关注`查全率`,因为一个健康人被误诊为不健康,可能仅仅只需要二次检测就能确认,而一个不健康的人被误诊为健康,可能就有生命危险了  
比如门禁检测,可能更加关注`查准率`,因为拦着了一个该进入的人,可能仅仅需要二次认定即可,而没有拦住一个不该进入的人,可能就会有重大危险了  

将`查全率`与`查准率`作为两个维度,就会产生一个二维坐标系  
此时,以`查全率`为横轴,`查准率`为纵轴,就是经典的`P-R图`  

`P-R`图能够形象的描述学习器在`PR`上的表现  
如果一个学习器A的PR曲线被完整的包括在另一个学习器曲线B的PR中,则可以判定学习器B全面优于A  

但事实上,大部分的PR曲线都难以呈现出优美的曲线,而往往体现为波浪,甚至是剧烈的断层  
这种情况下设计了一个综合考虑`查准率P`和`查全率R`的指标`平衡点BEP`(Break-Event Point)  
它是`查准率=查全率`时的取值,

### 回归学习  

在回归学习中,用`均分误差`来评估模型  


## 评估方法  

### 留出法  

`留出法`是直接将数据集分为两个互斥的集合.分别作为`测试集`和`训练集`(通常比例3:7)  

`留出法`的问题  
* 需要保证数据分布的一致性,避免因数据划分的过程引来数据偏差,从而对最终结果产生影响  
* 多种划分方式,可能带来不一样的训练结果,所以单次留出法的划分,可能结果不够稳定可靠  

所以留出法往往伴随多次随机划分,重复训练后取平均值作为留出法的评估结果  

### 交叉验证法  

`交叉验证法`是先将数据集划分为k个大小相似的互斥子集,每个子集自身尽可能保持数据分布一致性,然后每次选用k-1个子集数据作为训练集,剩余子集作为测试集,这样最终返回k个训练的均值  

`交叉验证法`的评估结果的稳定和准确,很大程度上取决于k的取值,为了强调这一点,通常`交叉验证法`又被称为`k折交叉验证`  
通常而言,k的一般取值是10,因此常用为`10折交叉验证`(其它常用取值还有5,20等等)  

与`留出法`类似,不同的数据划分方式,也会对最终结果产生影响,为了减少这种影响,`k折交叉验证`往往需要使用多种随机划分方式重复p次,然后对其结果取均值  
所以`交叉验证法`的最终结果一般为`p次k折交叉验证`  

### 留一法  

在`交叉验证法`中,假设k=m,则得到了`交叉验证法`的一种特例情况,称之为`留一法`  

* 优势  
显然,`留一法`不受数据划分方式的约束(因为不可能再有第二种划分方法了),也就是`留一法`没有p次概念,而这样的数据结果相对而言也认为是比较准确的  
* 劣势
`留一法`,在面对数据集本身较大时,将会产生巨大的计算开销  
其次,`留一法`的结果只能相对而言准确,不能认为是最准确的,`免费的午餐`定律对`留一法`同样有效  

### 自助法  

无论是`留出法`,还是`交叉验证法`都有一个必然问题是:训练集必然小于整个集合(训练集必然是集合的真子集)  
这带来的问题是必然会产生，因数据规模的不同而导致的估计误差（因为始终是使用部分数据进行训练，留一法只能尽可能将这种误差降小，但随之而来就是巨大的计算开销）  

`自助法`是直接以`自助采样法`为基础,对给定m个数据样本的数据集D,对其采样形成D'  
这里的采样过程是,每次从D中随机才一个样本,将其副本放入D',同时将其样本放回,这样的过程重复了m次后,就得到了一个m个样本的数据集D',这就是自助采样的结果  

显然,D'中的结果理论上是部分样本多次出现,部分样布永不出现  
估计样本中始终不被出现的概率是  

`$\lim_{n\rightarrow+\infty}\frac{1}{n(n+1)}$`

```
lim m→∞(1−1/m)m/1e≈0.368
```

即对任意集合数量而言,数据不出现的概率接近常数 36.8%  
也就是仍然有m个数据作为训练集,但同时保证有1/3的数据不在训练集中出现从而用于测试  
这种测试结果,也被称为 `包外统计`  

### 评估方法的选择  

`自助法`在面对数据集相对较小,难以有效划分训练测试集时比较好用,此外,`自助法`还能从数据集中产生多个不同的训练集,这对集成学习时非常有用,但`自助法`改变了初始数据的数据分布,这会引入估计偏差,所以在数据集比较充足时,`留出法`和`交叉验证法`更加常用    

### 调参与最终模型  

大多数学习算法都有参数需要设定,参数不同,学得模型的性能往往有显著区别  
所以进行模型评估与选择时,除了选择算法,往往还伴随着参数调节,这就是`调参`  

`调参`是模型中的重要一环,本质上算法选择与调参没什么区别,可以将算法选择细化为不同参数下的算法模型,然后在其中选择表现最优异的模型.这种思路本身是没有任何问题  
但实际过程中,这种思路却非常难以实现  
* 大型模型参数过多,很难为此为每一个参数建立模型然后进行评估  
* 某些算法参数是实数类型,也就是入参是无限的  

`调参`过程  



