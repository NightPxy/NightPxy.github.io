---
layout: post
title:  "离线数仓平台"
date:   2019-01-01 13:31:01 +0800
categories: project
tag: project
---

* content
{:toc}


--- 订单数据对账系统(离线ETL项目) ---  

## 背景描述  

采集第三方公司的订单数据,完成自动化的对账并给出订单差异明细和统计报表  

重难点  
* 各种第三方公司采集源差异非常大且不可能改变  
数据文件包括Excel,CSV,TXT,RAR(Excel),RAR(CSV),RAR(TXT),Zip(Excel)......等等  
数据列组织方式千差万别  
提供方式有FTP,OS系统下载,服务接口下载,部分甚至有爬网页的可能  
* 数据延时,订单结果可能会跨天体现(昨天的订单今天成功)  
* 全自动或可视化进行,尽可能减少人工干预,这其中的幂等性保证  
* 运营或财务等非技术人员使用  


## 资源评估    

### 数据规模  

* 单日数据总量不大  
毕竟这是订单对账文件而不是日志之类的,单日峰值在30G左右  
一单一条,但一条最终会产生三份(第三方一份,COP一份,子充值系统一份)  
* 数据日分布极不平衡  
每月1,2,3号,三天订单总量占比超过整月订单的60%  

### 集群规模  

现有大数据集群(YARN)共9台(8核64G),虚核映射1比3,排除系统保留资源后共计使用189C,540G  
YARN采用队列调度器,CM-YARN队列设定本项目最多使用 35C 100G

## 数仓平台设计  

### 架构  

![架构图](http://assets.processon.com/chart_image/5c3ea10ce4b0f430ae042e64.png)

数仓架构上大致由`存储`,`计算`和`调度`三部分组成   
* 数仓存储   
数仓存储包含`数据存储` 和 `元数据存储` 两部分  
* 计算规则  
ETL规则:描述外部数据到数仓的过程  
分析规则:描述数仓内部的表分析转换的过程  
* 作业调度  
规则本身是一种计算描述.规则将通过调度产生作业来真正执行  

### 元数据架构  

数仓元数据存储与MySQL中  
核心元数据的UML架构图如下  

![元数据](http://assets.processon.com/chart_image/5c3ec235e4b0fa03ce9b54ca.png)

* 存储元数据  
数据在数仓中统一按照 `库.表.分区.数据块` 结构存储  
`库`代表一个不同的HDFS集群或集群中某一个独立的目录  
`表`代表一组数据的统一集合,会有自己独立的格式,压缩方式,列信息,分区列等Schema信息  
`分区`代表业务领域中一个批次的数据文件集合  
`数据块`代表一个物理上的数据文件,数据血缘依赖也是以数据块为单位进行的 
* 计算规则元数据  
在现有数仓中,提炼出两种通用规则  `ETL规则` 和 `分析规则`  
`ETL规则` 描述的是采集(E),清洗(T),加载入库.表(L)的过程.  
`分析规则` 描述的是数仓内的数据分析和产出过程  
* 作业调度元数据  
规则的调度执行,一个规则将由一个调度器(Cron表达式),在某一个时刻将规则shell产生一个作业执行 


### 数仓存储  

数仓的存储包含`数据存储`与`元数据存储`两部分  
* 数仓数据存储于HDFS中  
* 数仓元数据存储与MySQL中  

### 计算规则

整个数仓的计算部分主要通过Spark完成  
* 对数仓内部而言,计算规则体现为两个部分 `shell脚本` 和 `相关参数设置`  
也就是说对数仓而言,计算的执行等价于设置相关参数执行一个shell脚本  
* 在数仓之外,计算体现为提前写好的可以被SparkSubmit提交执行的jar包  
也就是在数仓之外,计算的执行等价于Spark应用程序接收一些参数解析再执行  

这其中,会包装一些自定义的Spark外部数据源,来更好的完成执行  

`自定义Spark-FTP数据源(只读)`  
* 从相关设置上加载FTP信息(FTP地址,用户名,密码,路径,文件名,文件格式,分隔符)  
* 下载文件到本地磁盘,解压(Zip,Rar),利用SparkSQL读取本地文件为DataFrame[String]  
* 根据数仓表数据列,将 DataFrame[String] 转换为 DataFrame[DWSchema]  

`自定义Spark-JDBC数据源(只读)`  
* 自定义的分区读取数据(本质上就是分页SQL构建`JDBCRDD`)  
Spark内置的JDBC数据源的并行依赖某一个单一字段(数字或日期)的切片,不能满足要求  
自定义中主要改成利用RowNumber的传统分页方式切片读取  

### 作业调度(自研)  

#### 概述

数仓作业调度使用的是自研的分布式作业调度  
使用自研的是因为试过Azikaban等开源作业调度系统,有一个相对不能适用的问题在于很难自如的纳入数仓体系特别是数仓管理UI上,同时因为运营或财务人员的参与,也很难要求非技术人员进入一个纯专业调度系统进行操作  

#### 分布式设计 

该作业调度是一个分布式的主从架构(但保持程序节点一致,仅仅是主从节点各自启动不同的线程)  
* 主从节点的通讯选择基于消息队列(RabbitMQ)  
(没有使用Netty架构主从节点通讯网,维护Netty非常繁琐,而在这个作业调度系统主从间不需要端到端的定点通讯,只需要主节点广播出一个执行命令即可,不关心是谁执行这个命令)  
* 从节点扩容与HA  
从节点基于MQ订阅消息,直接扩容即可,HA类似  
* 主节点扩容与HA  
主节点为单节点,不支持扩容与HA  
(可以考虑做`去中心化`:引入ZK,做主节点的动态选举.这样主节点将在整个节点中流动,只要还存在两个以上节点就可以正常运行从而实现主节点的HA)  

主节点  
* 根据触发时间触发任务的执行,并通过RabbitMQ发送任务执行命令  
* 更新计算触发后的下次触发时间  
* 对外提供Rest服务,提供任务的编排制作,重跑,步骤完毕通知等  

从节点  
* 订阅任务执行消息,通过消息中命令Id从元数据中还原,执行命令(命令的本质是执行一段提前写好的shell脚本)  
* 从节点可以通过配置设置自己的最大同时消费线程数,来保护自己防止因为命令过度崩溃  

#### 调度执行设计  

作业调度的本质是一个基于时间有序的命令队列执行  
落地实现方面做的比较low,是基于DB轮询一个基于命令时间排序的数据表做的(但只会有主节点的一个线程的间隔轮询,在性能方面是没有问题的)  

#### 对外接口设计  

由主节点对外提供Rest服务  
* 作业编排,管理,重跑等WebUI对接  
* 执行中任务Metric  
* 步骤完成通知(启动下一步骤的触发)  

## 数仓平台应用(对账)

### 架构  

* 数仓  
通道订单对账过程最终实现为数仓中以订单对账为主题的离线ETL计算(数据集市)  
各通道订单数据通过`采集`和`预清洗`进入数仓  
经过`二次清洗` 成为 `通道订单事实数据`  
最终通过分析 `通道订单事实数据` 产生 `通道差异数据`  
* 外围系统  
为了简化采集难度,在数仓的对账应用上将引入一个外围系统  
设计采集的主方式为`FTP`或`JDBC`采集  
将其他异构方式(人工下载上传,爬网页等)在外围系统中推入公司内FTP,之后再按照主FTP方式进入后续流程  

在应用本身是以一个jar的形式体现,内部包含`采集&预清洗`,`二次清洗`,`对账差异计算`等多个Spark应用启动类,等待调度系统以Shell形式启动执行,  

### 数仓表(对账集市)   

![数仓表](http://assets.processon.com/chart_image/5c4e6398e4b0641c83eb7010.png)

* 通道原始数据表(`fact_channel_original`)  
`CSV`+`无压缩`,按照`采集日期`+`通道号`分区  
* 通道订单数据(`fact_channel_data`)  
`Parquet`+`Snappy`, 按照`通道号`+`订单日期`分区  
* 通道订单状态(`dim_order_status`),通道号(`dim_channel_no`)  
* 通道差异数据(`biz_channel_diff`)  
`CSV`+`无压缩`,按照`(通道号A+通道号B)升序`+`订单日期`分区  

### 采集与预清洗  

#### 执行过程  

采集过程的本质是一个Spark作业,采集结果写入`通道原始数据表`  
* 通过传入的ETL规则Id,还原规则信息  
FTP&JDBC等相关信息,目标表Schema,列清洗映射等等  
* 拉取数据,清洗转换为符合`通道原始数据表`Schema的DataFrame[Schema]  
* 按照`通道原始数据表`的文件格式(`CSV`),压缩方式(`无压缩`),分区列(`采集日期`+`通道号`)写到HDFS-tmp  
* 将HDFS-tmp移入`通道原始数据表`分区文件夹中 
* 更新`通道原始数据表`分区信息 和分区血缘关系  
* 更新`通道原始数据表`的统计信息   

#### 幂等  

* 重跑时,`通道原始数据表`的分区数据写入将采取覆盖写入  

#### 小文件  

采集与预清洗不考虑小文件问题  
* `通道原始数据表`每一个批次数据为一个独立文件  
* `通道原始数据表`只保留1个月数据,之后原始数据会进行完全删除  
原始数据的意义仅仅在于保证进入`通道订单数据`的准确性,在保留一个月之后已经基本确保`通道订单数据`,后续保留意义不大  

#### 资源申请(动态)  

采集与预清洗中  
* FTP  
限定一个Executor(1核4G),因为FTP不支持并行读,多Task读取没有意义  
* JDBC  
预执行SQL的Count计数,然后按照10万取模计算分区数  
取模算核数,核数取模5算executor数量  
最终计算出 executor数(5C4G)提交(上限4executor,也就是上限20C4G)  
内置的自定义JDBC数据源会自动做分页拉取  

### 二次清洗  

#### 执行过程  

`通道原始数据表`其实已经经过预清洗,已经完成了绝大部分的数据转换过程  
引入二次清洗主要是为了处理订单完成延时跨天问题,将原始表最终按照订单日期进行重分区清洗  
因为按照订单本身日期是后续主要业务要求,最终也将此作为基础事实表  

二次清洗在数仓中体现为一个分析规则  
二次清洗的本质是一个Spark作业,由一个shell脚本启动  
* 通过传入的分析规则Id,还原执行  
* 按照`通道订单数据事实表` 要求的格式,压缩和分区列重新分区, 写入HDFS-tmp  
* 根据HDFS-tmp构建分区信息与血缘依赖(详见下文幂等一节)   
* 将HDFS-tmp移入`通道订单数据事实表`文件夹中  
* 更新`通道订单数据事实表`的分区信息 和 血缘依赖关系  
* 更新`通道订单数据事实表`统计信息    


#### 格式&压缩  

二次清洗的输出结果为 `通道订单数据事实表`,采用Parquet+Snappy压缩  
* `通道订单数据事实表`属于原则上永久保留的数据(至少也是保存半年或一年)  
采用压缩可以更好的节约磁盘空间   
采用Snappy压缩是因为压缩后文件不大,没有使用随机读的必要  
* Parquet文件格式  
Parquet自带Schema信息,且支持分区推断和谓词下推,在Spark计算中非常方便  
Parquet的列式存储可以为Snappy带来更好的压缩比  
Parquet的不可阅读缺点在作为事实表时不成问题,因为事实表不需要直接阅读  

#### 幂等  

二次清洗的重跑计算是依据`通道原始数据表`某个采集批次进行计算  
所以二次清洗的幂等主要是针对 `通道原始数据表`采集批次 的重跑幂等  

二次清洗过程中,因为订单跨天充值延时的问题,所以某一个批次的`通道原始数据表`清洗写入`通道订单数据事实表`,可能会最终产生跨越多个分区,而对于`通道订单数据事实表`某一个分区而言,可能是由`通道原始数据表`多个批次汇聚而成  

因此二次清洗的本质是找出某个原始批次产生的数据进行删除,之后再重新导入该批次数据  
对于原始批次与事实数据的关系,依赖`通道订单数据事实表`的血缘关系  
过程如下  
* 在`通道原始数据表`拉取计算写入HDFS-Tmp后  
先通过元数据扫描出`通道订单数据事实表`数据块中依赖该批次的数据块  
* 将依赖该批次的数据块删除(HDFS数据+分区依赖元数据)  
* 从HDFS-Tmp中扫描文件(数据文件与文件所属目录),重新构建数据块血缘依赖  
分区路径=>文件目录  
数据块文件=>数据文件  
依赖数据块=>来自当前拉取的`通道原始数据表`批次  
* 重新构建的数据块依赖血缘写入元数据(必须元数据优先)  
* 数据块依赖血缘写入完毕后,将HDFS-Tmp移入 `通道订单数据事实表` 目录  

二次清洗幂等有一个问题  
只能在1个月内维持幂等(一个月内将会因为小文件合并而破坏重跑幂等(数据重复),下文详述)  

#### 小文件  

二次清洗过程中,因为订单跨天充值延时的问题所以小文件问题是非常严重的(基本每天每个通道都会有数量不等的订单延时)  

这里的判定比较粗暴  
* `通道订单数据事实表` 规定每一个分区下最终只会有且仅有一个文件(数据块)  
因为`通道`+`订单日期批次`下的总数据量不大(原始最大才五六百M,压缩一百多)  
*  不做跨分区合并 分区下的最后一个文件再小也不再合并  
因为以天做为批次维度,小文件数量上限始终有限  

小文件的合并依赖分区血缘元数据,具体处理如下  
* `通道订单数据事实表`的小文件合并视为一个分析规则,本质是一个Spark作业  
* 统计`通道订单数据事实表`分区下数据块信息(`group by ... count > 1`)  
扫描出分区下文件数大于1的分区,作为需要合并的工作分区  
* 逐个读取需合并的分区,将分区下的所有数据文件通道Spark读取再coalesce(1)写出到HDFS-tmp  
小文件合并后数据文件名固定为 `xxx.merge`  
* 删除分区下数据块元数据(HDFS不删除)  
* 重新构建数据块元数据  
分区路径(分区键值)=>文件目录  
数据文件=>数据文件(固定为 `xxx.merge`)  
依赖数据块=> 设为null(合并之后数据块必须打断血缘依赖)    
* 构建的数据块新的依赖写入元数据
* 删除分区原数据块后HDFS-tmp重新移入 `通道订单数据事实表`分区目录  

二次清洗的小文件合并是一个延时作业(延时相当长,一个月以上)  
这是因为这个小文件合并会破坏幂等性,所以必须等待时间足够长确定没有问题之后才能合并  
一旦完成合并,分区数据会立即打断依赖关系  

### 差异计算

#### 执行过程

差异计算在数仓中体现为一个分析规则  
差异计算的本质是一个Spark作业,由一个shell脚本启动  
差异计算输出将会有两个输出端 差异CSV文件(HDFS) 和 统计报表(MySQL)  

差异计算的具体过程如下:  
* 根据传入的分析作业Id,读取还原相关信息  
数据源表:
执行相关:`通道号(两个)`与`日期批次`   
输出  
* 从`通道订单数据事实表`读取两个目标通道指定日期批次的数据为DataFrame  
* 两个DataFrame的两次 `LEFT JOIN` 结果为差异结果  
* 差异结果本身写入 `通道订单差异数据(上层业务)` 表  
* 差异结果的统计信息(`差异订单数`,`总差异金额`,`最大差异金额`等等)写入MySQL     

#### 资源申请(动态)  

* 读取`通道订单数据事实表.数据块`元数据上的`记录总数`  
* `记录总数`取模100万设计为`分区数`  
* `分区数` 除以20作为作业`核数`(上限20)  
* `核数`除以5作为 executor数量,每个executor设定内存4G  

最终按照 `通道订单数据事实表.数据块.记录总数`动态动态申请资源,并且最多使用5个executor(每个executor上限5C4G)  
这样的目的是依据通道实际单量申请资源(依据通道本身申请资源没有意义,业务上可能这个通道今天跑的多,明天那个通道跑的多)  

#### 格式&压缩  

差异计算结果使用的 `CSV` + `无压缩`  
原因如下  
* 差异数据的单位数据量非常非常小,这是后续选择的一个最最重要的指标  
* 差异数据会交由运营或财务人员直接下载阅读,对于这些人员而言最友好的方式是`CSV`  
* 数据量太小所以不压缩.HDFS直接以原文件存储这在WebUI上下载文件时可以直接用HDFS的文件流写入Http输出流,中间不用任何转换工作  

#### 缓存&方式  

两个目标通道指定日期批次DataFrame,差异结果DataFrame 都使用DataFrame缓存  
因为从计算过程中每一个DataFrame都使用了不止一次  
* 通道指定日期批次的DataFrame,会有**两次**左连接计算差异来汇总差异结果  
* 差异结果DataFrame,会有**两次**输出操作(差异文件写出和统计)  

缓存使用内存序列化缓存(Kyro方式),我们是小集群,所以基于以下考虑  
* 小集群的磁盘和网络都比较紧张  
特别是网络方面,我们集群是与业务系统在一个机房里的,所以必须尽可能控制自身的网络传输带宽  
* 任务相对不繁重  
总的来说,集群的计算任务相对不重,这代表集群的CPU能力本身是富裕的  

#### 幂等  

差异计算的幂等体现在如下方面  
* 差异计算的HDFS输出幂等  
差异结果的HDFS输出将始终按照`通道号(两个升序)`与`日期批次`维持分区目录覆盖输出  
* 差异计算的MySQL输出幂等  
差异结果的MySQL输出将始终按照`通道号(两个升序)`与`日期批次`字段维持单条语句的`replace into` 写入  

#### 小文件   

正常来说,差异数据量都是非常少的,每一个差异结果单位的DataFrame写出都会coalesce(1)  
<font color=red>这里比较纠结,从业务上来说,两个通道订单的某批次差异是一个业务上独立的数据单位,差异下载也是按这个单位下载的,所以是一个单位形成一个独立的文件  
但是这个差异数据量太小了,正常可能就几条或几十条差异不等,一个差异文件总共可能就几KB或十几KB  
业务上独立写入和独立下载,个数明确不会膨胀(一天一个),但就是数据太小,这种算不算小文件呢?  
</font>


#### 倾斜    

通道订单数据join有可能会产生倾斜问题  
但通道订单数据join不可能产生同Key倾斜,只可能产生同分区倾斜.(因为join-key是订单号,唯一但不保持连续)  

所以通道订单数据join的倾斜处理起来非常简单,`调整join分区数`就行了  
这里如果需要可以再扯下join的其它倾斜处理方案  
* BoardCast-Join  
* 协同分区的思路  
* 随机Key+小表膨胀  


## WebUI 

### 概述  

* AngularJS 作为UI层前端主框架,整合多个微服务系统的Rest(注意下跨域即可)  
* SSO  

### 技术向  

* 数仓元数据管理  
* 规则管理(ETL规则,分析规则,规则不同基于不同的模板(Angular自定义指令))  
* 规则的自定义参数立即触发  
* 规则的调度管理(一个规则=>多个调度规则(Cron表达式))  
* 当前作业池与调度日志查询  

### 非技术向  

* 通道对账报表  
* 以`通道+日期批次`的对账但下载  
* 对已经执行过的`通道+日期批次`的任务重跑  


## 扩展    

### 更多的规则封装  

譬如小文件合并,是在业务主题(对账集市)中完成的  
但小文件合并,本身是可以借助数据元数据(`分区.数据块+统计信息`)做到无视业务工作的  
这个代表小文件合并可以抽离为独立规则,配置小文件判定指标,合并数量,扫描规则等等在业务之外独立运行  

### 规则SQL表达  

现在的规则过程是架构在MySQL之上的  
规则特别是分析规则,语义非常匮乏,很难用结构化元数据表达(比如一个JDBC就得独立成表,难受)   
未来可以引入SQL化,借助SQL的丰富语义来描述负责的规则过程.  
这其中Spark自定义数据源,特别是结构化流系的会占据一个非常核心的位置  

两个框架是未来研究的重点  `Apache Calcite` 和 `Spark Waterdrop`  

### 数据质量监控&告警  

在血缘产生上采集更多的过程信息  诸如 `抛弃数`,`空值填充数`,`补全数`等等  
只要数据质量信息能够在元数据中体现,监控与告警无论是新开规则还是依附原有规则都是相对容易的  

### 调度作业系统内执行  

现在是在调度系统外部(`shell`)执行调度任务,虽然简单但很难感知任务的最终处理结果  
在任务内回调通知任务结束这个方案并不理想(造成侵入任务)  
如果在调度系统内部内执行(`反射`),就可以很好的监控到具体的作业执行情况,但是这个工作量太过吓人,资源的申请释放,崩溃,jar传输,协同,容灾等等,还是应该找个合适的开源框架改改然后嵌入  


## 问题  

### 血缘依赖抽象 

<font color=red>血缘依赖这里抽象非常不理想,这是最不满意的地方  
血缘这块我的理解</font>   
* <font color=red>部分来自Spark的RDD血缘上的学习</font>  
* <font color=red>部分来自基于血缘做幂等重跑的业务倒推</font>  

<font color=red>最终血缘依赖选择以`数据文件`为核心,但这里的抽象非常不理想,只是倒推来的折中方案</font>  
* <font color=red>以`表`为单位,表内数据血缘可能完全不同. 以表为单位非常空泛,很难产生实际价值</font>   
* <font color=red>以`分区`为单位本来是首选,但因为数据延时,分区内数据也可能来自不同地方</font>  
* <font color=red>以`数据文件`粒度足够了,但数据文件之间的关系完全可能是多对多,这带来的血缘依赖关系非常非常复杂</font>    

<font color=red>期待有更好的思路</font>  

### 数据存储元数据  

<font color=red>数据存储元数据是自己设计的  
使用`Hive-MetaStore`应该是更好的方案,这样在SparkSQL或者更换计算引擎会会更加方便  
但`Hive-MetaStore`并不能完全满足要求,譬如没有`数据文件`这一级,血缘关系应该怎么做呢  
唉 总之非常纠结</font>  
