---
layout: post
title:  "Spark-日志监控"
date:   2018-06-06 13:31:01 +0800
categories: spark
tag: spark
---

* content
{:toc}


##   Spark-监控  

### Application-WebUI  

每个SparkContext都会暴露一个WebUI(默认4040,依次叠加),用以展示这个Application的运行过程的一些重要信息,这包括:  
* 每个RDD的大小和内存占用量  
* Application的环境信息  
* 每个executor的信息  
* Spark任务调度器的Task和Stage列表  

但是这里有个问题,SparkContext会随着应用程序关闭而关闭,也就是Application一旦执行结束,就无法查看应用程序了  

### Spark-历史日志  

#### 启用  

Spark内置了一个历史日志服务,可以查看Spark的历史任务日志  

```shell
./sbin/start-history-server.sh
```

启动这个服务前,需要开启任务日志写入历史库  

```shell
cp /home/hadoop/app/spark-2.3.1-bin-2.6.0-cdh5.7.0/conf/spark-defaults.conf.template /home/hadoop/app/spark-2.3.1-bin-2.6.0-cdh5.7.0/conf/spark-defaults.conf

vi /home/hadoop/app/spark-2.3.1-bin-2.6.0-cdh5.7.0/conf/spark-defaults.conf

spark.eventLog.enabled           true
spark.eventLog.dir               hdfs://hadoop000:9000/spark/event-logs
spark.history.fs.logDirectory hdfs://hadoop000:9000/spark/event-logs
spark.history.ui.port  18080
spark.history.fs.cleaner.enabled	true

```



spark.eventLog.enabled true  
spark.eventLog.dir hdfs://namenode/shared/spark-logs  

#### 详细配置  

**环境配置**  

|配置项 |描述|
|---|---|
|SPARK_DAEMON_MEMORY|history server 内存分配（默认值：1g）|
|SPARK_DAEMON_JAVA_OPTS|history server JVM选项（默认值：无）|
|SPARK_PUBLIC_DNS|history server 公共地址。如果没有设置，应用程序历史记录的链接可能会使用服务器的内部地址，导致链接断开（默认值：无）|
|SPARK_HISTORY_OPTS|spark.history.* history server 配置选项（默认值：无）|

**Spark配置**  

|配置项 |描述|
|---|---|
|spark.history.provider|执行应用程序历史后端的类的名称.目前只有一个实现(org.apache.spark.deploy.history.FsHistoryProvider)，由Spark提供，它查找存储在文件系统中的应用程序日志|
|spark.history.fs.logDirectory|要加载的应用程序事件日志的目录.可以是本地文件系统或任何Hadoop支持的分布式文件系统|
|spark.history.fs.update.interval|在日志目录中检查新的或更新的日志间隔区间.默认10S|
|spark.history.retainedApplications|在缓存中保留UI数据的应用程序数量.如果超出此上限，则最早的应用程序将从缓存中删除(删除后从磁盘读取) 默认50 |
|spark.history.ui.maxApplications|在历史记录摘要页面上显示的应用程序数量 默认Int.Max |
|spark.history.ui.port|history server 的Web界面绑定的端口 默认18080|
|spark.history.fs.cleaner.enabled|指定 History Server是否应该定期从存储中清除事件日志 默认false|
|spark.history.fs.cleaner.interval|job history清洁程序检查要删除的文件的时间间隔 默认1d|
|spark.history.fs.cleaner.maxAge|history保留时间,超出这个时间江北清洁程序删除 默认7d|
|spark.history.fs.numReplayThreads |history server 用于处理事件日志的线程数 默认25%的可用核 |

#### 注意  

* history server 显示完成的和未完成的Spark作业  
如果应用程序在失败后进行多次尝试,将显示失败的尝试,以及任何持续未完成的尝试或最终成功的尝试  
* 未完成的程序只会间歇性地更新.  
更新的时间间隔由更改文件的检查间隔 (spark.history.fs.update.interval) 定义,在较大的集群上，更新间隔可能设置为较大的值  
* 没有注册完成就退出的应用程序将被列出为未完成的,即使它们不再运行.如果应用程序崩溃,可能会发生这种情况  
* 一个用于表示完成Spark作业的一种方法是明确地停止Spark Context (sc.stop()),或者在Python中使用 with SparkContext() as sc


