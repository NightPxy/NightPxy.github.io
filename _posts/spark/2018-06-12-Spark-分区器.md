---
layout: post
title:  "Spark-分区器"
date:   2018-06-12 13:31:01 +0800
categories: spark
tag: spark
---

* content
{:toc}


## 分区器  

分区器是RDD的重要组成部分,因为RDD本身是由分区构成,控制数据分布的核心就是分区器  
控制好的分区器可以减少shuffle网络传输,或者一些特殊的数据分组等等  

## 内置的分区器  

### HashPartitioner  

HashPartitioner 的分区策略是,对于给定的Key,计算其HashCode,并除以分区的个数取余.如果其HashCode为负数,则用余数+分区个数  

注意:  
数组类型的HashCode,是基于其数组对象本身而不是内容,因此用HashPartitioner分区数组类型RDD,可能会生成错误的结果  


```scala

//Key计算策略
def nonNegativeMod(x: Int, mod: Int): Int = {
    val rawMod = x % mod
    rawMod + (if (rawMod < 0) mod else 0)
}
  
class HashPartitioner(partitions: Int) extends Partitioner {
  require(partitions >= 0, s"Number of partitions ($partitions) cannot be negative.")

  def numPartitions: Int = partitions

  def getPartition(key: Any): Int = key match {
    case null => 0
    case _ => Utils.nonNegativeMod(key.hashCode, numPartitions)
  }

  override def equals(other: Any): Boolean = other match {
    case h: HashPartitioner =>
      h.numPartitions == numPartitions
    case _ =>
      false
  }

  override def hashCode: Int = numPartitions
}
```
### RangePartitioner  

RangePartitioner 的分区策略是一种随机抽样策略.(水塘算法抽样) 

**水塘算法**

在取第n个数据的时候，我们生成一个0到1的随机数p，如果p小于1/n，保留第n个数。大于1/n，继续保留前面的数。直到数据流结束，返回此数  

大致算法如下:
* 设定取出的行号为choice  
* 第一次直接以第一行作为取出行 choice  
* 而后第二次以二分之一概率决定是否用第二行替换 choice  
* 第三次以三分之一的概率决定是否以第三行替换 choice  
* 以此类推  

这种抽验算法的好处是在不知道元素总个数的情况下进行抽样  


## 自定义分区器  

自定义分区器需要继承实现Partitioner抽象类   

