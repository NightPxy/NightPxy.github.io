---
layout: post
title:  "Spark-编译(2.3.1)&部署(YARN-Cluster)"
date:   2018-07-01 13:31:01 +0800
categories: spark
tag: 编译&部署
---

* content
{:toc}



Spark编译(2.3.1)&部署(YARN-Cluster)
------------------------

## 前置准备 

1. **Maven 3.3.9**
Maven需要将内存使用调高(防止编译过程内存超标报错)
export MAVEN_OPTS="-Xmx2g -XX:ReservedCodeCacheSize=512m"
2. Java 8+
必须,Spark2.2.0开始就已经不支持 Java7 了
3. Git
最好装上,编译不需要.但做部署包是需要Git的

---
## Scala 准备
Spark本身使用Scala写的,也需要Scala语言的支持.
Spark 2.3.1需要的Scala版本是 2.11+.这里我选择的是2.11.8

官网下载: 
> https://downloads.lightbend.com/scala/2.11.8/scala-2.11.8.tgz

解压 
> tar -xzvf ~/software/scala-2.11.8.tgz -C ~/app 

写入环境变量:
> export SCALA_HOME=/home/hadoop/app/scala-2.11.8
> export PATH=$SCALA_HOME/bin:$PATH

---
## 编译
### 下载 Spark 源码
这里选择的当前最新版  spark-2.3.1.tgz
解压
>tar -xzvf ~/source/spark-2.3.1.tgz -C ~/source/

### Spark pom.xml
Hadoop我使用的CDH版
所以在pom.xml中加入cloudera仓库地址以便正确下载Hadoop.CDH Jar包
>&lt;repositories&gt;
>  &lt;repository&gt;
>    &lt;id&gt;cloudera&gt;/id&gt;
>    &lt;url&gt;https://repository.cloudera.com/artifactory/cloudera-repos/&lt;/url&gt;
>  &lt;/repository&gt;
>&lt;/repositories&gt;

### 调制 Spark 版本参数
Spark2.3.1 本身的 Hadoop版本是2.6.5
这里需要调整下,因为我的Hadoop是 2.6.0
> hadoop.version=hadoop-2.6.0-cdh5.7.0 (我的YARN与Hadoop版本相同)
> hive.version=hive-1.1.0-cdh5.7.0

### 编译
Maven编译命令
>./build/mvn -Pyarn -Phadoop-2.6 -Dhadoop.version=2.6.0-cdh5.7.0 -Phive -Phive-thriftserver -DskipTests clean package

### 部署包
>./dev/make-distribution.sh --name 2.6.0-cdh5.7.0  --tgz -Pyarn -Phadoop-2.6 -Dhadoop.version=2.6.0-cdh5.7.0 -Phive -Phive-thriftserver

第一次编译耗时比较久,建议科学上网,最后的结果如下
![编译结果](/images/spark/Spark-编译部署/编译结果.png)

## 部署
Spark有三种部署模式,选择部署为YARN-cluster模式
部署包拷贝到software(我统一放安装的包的地方)
>cp ./spark-2.3.1-bin-2.6.0-cdh5.7.0.tgz ~/software/

解压
>tar -xzvf ~/software/spark-2.3.1-bin-2.6.0-cdh5.7.0.tgz -C ~/app

配置环境变量
>export HADOOP_CONF_DIR=/home/hadoop/app/hadoop-2.6.0-cdh5.7.0/etc/hadoop
>export SPARK_HOME=/home/hadoop/app/spark-2.3.1-bin-2.6.0-cdh5.7.0
>export PATH=$SPARK_HOME/bin:$PATH

拷贝Spark配置模板
>cp ~/app/spark-2.3.1-bin-2.6.0-cdh5.7.0/conf/spark-env.sh.template  ~/app/spark-2.3.1-bin-2.6.0-cdh5.7.0/conf/spark-env.sh

编辑Spark配置文件
>vi ~/app/spark-2.3.1-bin-2.6.0-cdh5.7.0/conf/spark-env.sh

编辑如下(请依据自身情况配置,我这里是测试机,配置非常低)
> export JAVA_HOME=/home/hadoop/app/jdk1.8.0_45
> export HADOOP_CONF_DIR=/home/hadoop/app/hadoop-2.6.0-cdh5.7.0/etc/hadoop
> export YARN_CONF_DIR=/home/hadoop/app/hadoop-2.6.0-cdh5.7.0/etc/hadoop
> export SPARK_EXECUTOR_CORES=1
> export SPARK_EXECUTOR_MEMORY=1G
> export SPARK_DRIVER_MEMORY=1G

拷贝Slayer配置
>cp ~/app/spark-2.3.1-bin-2.6.0-cdh5.7.0/conf/slaves.template ~/app/spark-2.3.1-bin-2.6.0-cdh5.7.0/conf/slaves

编辑Slayer配置
>vi ~/app/spark-2.3.1-bin-2.6.0-cdh5.7.0/conf/slaves

编辑如下
>hadoop000

## 启动
启动Spark-Shell
![Spark-Shell启动界面](/images/spark/Spark-编译部署/Spark-Shell启动界面.png)
![Spark--Web启动界面](/images/spark/Spark-编译部署/Spark-Web启动界面.png)

启动服务
![Spark-Service启动界面](/images/spark/Spark-编译部署/Spark-Job启动界面.png)

测试任务
>./bin/spark-submit --class org.apache.spark.examples.SparkPi \
>--master yarn \
>-deploy-mode cluster \
>--driver-memory 1g \
>--executor-memory 1g \
>--executor-cores 1 \
>--queue thequeue \
>examples/jars/spark-examples*.jar \
>10

![Spark-YARN](/images/spark/Spark-编译部署/Spark YARN.png)
