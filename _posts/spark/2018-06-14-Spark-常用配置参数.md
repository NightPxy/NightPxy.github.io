---
layout: post
title:  "Spark(2.3)-常用配置参数"
date:   2018-06-11 13:31:01 +0800
categories: spark
tag: spark
---

* content
{:toc}


## 压缩  

* `spark.io.compression.codec` 默认`lz4` 可选(`lz4`,`lzf`,`snappy`,`zstd`)   
广播变量压缩(`spark.boardcast.compress`,true)会使用该配置的压缩方式  
RDD缓存压缩(`spark.rdd.compress`,false)会使用该配置的压缩方式  
Shuffle-Map输出压缩(`spark.shuffle.compress`,true)会使用该配置的压缩方式  
Shuffle-Spill压缩(`spark.shuffle.spill.compress`,true)会使用该配置的压缩方式  
event-log压缩(`spark.eventLog.compress`,false)会使用该配置的压缩方式  
* `spark.io.compression.lz4.blockSize` 默认32K  
`spark.io.compression.snappy.blockSize` 默认32K 
使用`lz4`或`snappy`压缩时的压缩块大小  

## 序列化  

* `spark.serializer`使用的序列化器 默认JavaSerializer.可选Kyro  
如果使用Kryo可以不从这里设置,而在`conf.registerKryoClasses()`注册类型时会自动转换`spark.serializer`为Kryo序列化器  

## 内存管理  

* `spark.memory.fraction` Spark内存占据JVM堆比例,默认0.6  
Spark内存是一个泛概念,实际指 `Spark存储内存`+`Spark执行内存`的总和  
* `spark.memory.storageFraction` Spark存储内存占Spark内存比率,默认0.5  
没有特指的`Spark执行内存`设置(Spark剩余内存即是)  
一般来说需要压低`Spark存储内存`,特别是缓存使用较少但大量使用shuffle的情况  
`存储内存`占比0.5有点偏高,存储的LRU算法容易造成伪内存泄露,也不利于GC  
`执行内存`占比0.5又有点偏低,无论是Shuffle还是排序聚合消耗的都是`执行内存`(Spark2.X的动态资源调度没有再特指`Shuffle内存`,而是将其统一移入了`执行内存`)  

## 执行  

### 并行度  
* `spark.default.parallelism`  默认并行度(**非常重要**)  
**默认并行度**指的是Spark中的无法通过上级推断出并行度的场景,作为默认并行度   
比如byKey或join等Shuffle场景(无法推断Key数量),又或者Spark读取一个本地文件(非HDFS),并且用户也没有特别在方法调用时指定并行度的时候  
**默认并行度的默认值** 是一个动态计算值,计算规则如下   
`本地模式`为核数,`Mesos细粒度`为8,其它(包括`YARN`)为所有executor核总数(或2,谁大取谁)  

### 资源  
* `spark.executor.cores` executor的核数(YARN下默认为1)   
* `spark.executor.heartbeatInterval` executor对driver的心跳间隔,默认10S  

### 调度  

## 网络  
* `spark.netwrok.timeout`  执行的默认最大超时时间,最大120S 
这个默认值本身没有意义,但会作为以下配置的默认值  
`spark.core.connection.ack.wait.timeout` 连接在超时和放弃之前等待ACK响应时间  
`spark.storage.blockManagerSlaveTimeoutMs``BlockManagerSlaver`超时时间   
`spark.shuffle.io.connectionTimeout`  
`spark.rpc.askTimeout`RPC请求超时时间   
`spark.rpc.lookupTimeout`  
* `spark.rpc.numRetries`RPC请求的重试此时,默认3次,可以适当调高  
* `spark.rpc.retry.wait`PRC请求的创世间隔,默认3S  

## Shuffle    

### Map 

* `spark.shuffle.file.buffer` 文件溢写缓冲大小 默认32K   
如果内存充足可以适当调大,这可以减少Map端文件溢写次数  

### Reduce

* `spark.shuffle.io.maxReties` 默认3次  
这是拉取请求的错误重试次数,一般可以适当调大(30次)  
因为网络波动或目标executor处于GC过程导致不可访问,shuffle请求很可能不成功,调大可以提高稳定性  
*  `spark.shuffle.io.retryWait` 默认5S  
这是拉取请求的最大超时时间,一般可以适当调大(30S),原因同上  
* `spark.reducer.maxSizeInFlight` 默认48M  
拉取请求的缓冲块(一次拉取多少大小的数据),如果内存充足可以适当调大,可以减少拉取次数  
* `spark.reducer.maxBlocksInFlightPerAddress` 默认`Int.Max`  
每个主机(Address)可以被多少个Reducer主机(Address)拉取数据,在大集群中可以适当调低来降低某个热点executor的压力  
* `spark.reducer.maxReqsInFlight`  默认 `Int.Max`  
每个主机(Address)可以接收多少个Reducer拉取请求,大集群中可以适当调低来降低某个热点executor的压力  

### 内存&压缩  

* Spark1.6 `spark.shuffle.io.memoryFraction` 默认0.2 适当调大   
Spark2.X  `spark.memory,storageFracation` 默认0.5,适当压低  
Spark2.X是动态内存管理,Shuffle是占据执行内存的一部分,通过压低存储内存可以调高执行内存  
* `spark.shuffle.compress` Map输出压缩,默认true  
* `spark.shuffle.spill.compress` 溢写压缩,默认true  
* `spark.shuffle.consolidateFiles` 默认false ,可以设为true  
这是在Spark2.x已经废弃,但老版本可以使用的优化,在使用优化版的Hash-Shuffle  





https://blog.csdn.net/zyzzxycj/article/details/81011540
https://blog.csdn.net/u012102306/article/details/51637366