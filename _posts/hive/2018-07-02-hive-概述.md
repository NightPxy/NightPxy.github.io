---
layout: post
title:  "Hive 概述"
date:   2018-07-02 13:31:01 +0800
categories: hive
tag: hive
---

* content
{:toc}


# Hive简述  

## Hive是什么  
Hive是构建在Hadoop之上的数据仓库.  
它通过解析QL(Hive SQL),转换成MR任务(Tez,Spark......)去提交到Hadoop上去执行  

## Hive的优缺点以及适用场景   

**优点**  
* 直接访问HDFS,或者其它的标准分布式文件系统(s3,oss等),并将这些分布式文件数据组织成表的形式  
* 传统的MR任务编写,非常复杂,需要很高的学习成本.Hive的出现,可以将MR的任务编写转换成类SQL的形式,降低了学习和使用成本  
* Hadoop良好的容灾能力和可扩展能力,几乎不受限制的数据处理量.因为它实际存储使用的HDFS,实际计算使用的MR  
* 提供统一的元数据管理  

**缺点**  
* 执行的效率一般.因为它是转换为MR提交执行,受执行计划生产的影响,它最后执行的不一定是最优的解决方案  
* 计算的及时性差.还是因为转换为MR提交执行,受MR执行效率影响(申请资源,走MR执行流程等等),Hive的计算,就算是小数据量,计算时间也偏长  
* 相对于关系型数据库的SQL而言,Hive的类SQL表达能力一般  
* 很难支持行级别的数据更新  

**适用场景**  
> Hive不擅长使用在对计算及时性要求非常高的地方(实时计算),并且也不擅长使用在小数据量上  
因为它哪怕就计算几条数据,也要耗费大量的资源(必然SQL解析,生成MR,提交到YARN,申请资源,MR执行等等流程)  
> 它比较擅长于用在能接受较长的延迟性,大数据量的批处理作业.比如离线日志分析等  
> 或是不执行任何MR操作的查询使用,彻底转为分布式文件系统的一个查询媒介(其实这种都不推荐Hive)  

# Hive的架构  

## 元数据  
Hive是整体运行在Hadoop之上的.实际处理的是HDFS中的文件数据.除了存储在HDFS上数据本身以为,还存有一份数据的元数据  
元数据是用来标记HDFS中数据的schema信息.计算节点在执行MR任务中,会依据这份schema信息来标识如何具体的使用数据.  

> 实际生产过程中,元数据库必须做好高可用  
> 因为数据本身的容灾能力很强(基于Hadoop)  
> 但如果元数据库不能使用,Hive依然不能正常读取运行.这很容易成为Hive中的瓶颈  

## 执行过程  
* 解析收到的SQL,生成一个抽象语法树  
* 依据抽象语法树,生成逻辑执行计划  
* 优化器优化逻辑执行计划,比如合并可同步进行的操作等  
* 生成物理执行计划=>MR任务  
* 将MR任务提交到YARN上执行  

# Hive的存储

## 元数据库  
Hive的元数据是存储在关系型数据中的,默认是Derby,但一般使用的MySQL  

## 数据的存储  
Hive的数据本身存储在HDFS中.
由配置节 ***hive.metastore.warehouse.dir*** 控制,默认是存储在 /usr/hive/warehouse 中  

Hive本身的数据库/表/分区/桶等概念,分别在HDFS上体现为文件夹  
所以 DataBase.Table的数据 实际体现为 /Database(文件夹)/Table(文件夹)/XXXX(文件,可以有多个)  