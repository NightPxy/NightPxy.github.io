---
layout: post
title:  "提纲"
date:   2018-09-01 13:31:01 +0800
categories: interview
tag: spark
---

* content
{:toc}


# Spark  

## 基础篇  

大数据常用端口  

* RDD的分布式弹性数据集体现  
* RDD的五大特性以及体现  
* 常用RDD简述  
* RDD的分区数计算  
* RDD的缓存是立即进行吗,缓存级别有哪些以及如何选择  
* RDD结构以及源码简述   
* BlockManager怎么管理硬盘和内存的  
* RDD的宽依赖与窄依赖,有什么区别,Join是宽还是窄依赖  
* Spark是如何分解出DAG图的  
* Spark的DAG图是如何调度执行的  
* Spark的内存管理  
* Spark的OOM一般有哪些,如何处理  
* 哪些算子会有Shuffle  
* Streaming的运行架构  

### Core  

Spark与MR的优劣对比,以及各自的适用场景  

3. 常用RDD简述  
4. RDD的计算过程(转换,操作以及血缘关系的体现和大致流程)  
5. RDD的容错机制简述    
7. 广播变量与累加器简述  
8. 
9.   
9. Spark的缓存机制(各模块缓存默认级别)与检查点  
10. Spark的Shuffle读写过程.有哪些模式如何调优,,与MR的shuffle有什么区别   

RDD的算子combineByKeyWithClassTag简述  
介绍一下cogroup rdd实现原理

SparkSQL的优势  
通用SQL执行原理以及在Spark中SQL的执行过程  

Sreaming Kafka的两种模式比较  

Spark的动态资源调度
Spark的数据本地性有哪些


Spark哪些情况可能会发生倾斜,如何处理  
SparkSubmit的常用参数有哪些 
join的优化  
Spark的优化

13、为什么Spark Application在没有获得足够的资源，job就开始执行了，可能会导致什么什么问题发生?
答：会导致执行该job时候集群资源不足，导致执行job结束也没有分配足够的资源，分配了部分Executor，该job就开始执行task，应该是task的调度线程和Executor资源申请是异步的；如果想等待申请完所有的资源再执行job的：需要将spark.scheduler.maxRegisteredResourcesWaitingTime设置的很大；spark.scheduler.minRegisteredResourcesRatio 设置为1，但是应该结合实际考虑否则很容易出现长时间分配不到资源，job一直不能运行的情况。

5个partition里面分布有12345678910.用算子求最大值或者和。不能用广播变量和累加器。或者sortbykey
Spark的全局TopN,二次排序  

HDFS的有几个Block就有几个Partition,这个说法对不对  

### 架构  

1. Spark架构中包含哪些组件,简述它们之间的关系  
2. Spark的作业执行过程简述(YARN模式为主,两种YARN模式)  
3. Spark的内存管理()

## 进阶篇  

1. Spark的作业执行过程详述  


## 高级篇  
1. 简述DAG绘制过程  


## 终极篇  
1. SparkCore的架构基础体系(源码)(通讯,计算执行,调度和存储)  

# JavaEE  

## IO  

1. IO模型有哪些?Reactor和Proactor模式简述,区别,场景,实现    

## 线程池  
JDK自带哪些线程池,如何实现一个自己的线程池  
1. 线程池的优势.默认线程池实现的优劣,默认有哪些阻塞策略和拒绝策略)  \
2. 线程模型的演进

# Scala  

1. 闭包.闭包在一个JVM和分布式应用场景下
2. implicit  
3. 柯里化函数  
