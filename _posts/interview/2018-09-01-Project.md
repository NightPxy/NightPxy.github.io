---
layout: post
title:  "Project"
date:   2018-09-01 13:31:01 +0800
categories: interview
tag: spark
---

* content
{:toc}


# 订单数据对账系统(离线ETL项目)   

## 项目背景  

采集第三方公司的订单数据,与公司订单完成自动化的对账并给出订单差异明细和统计报表  

重难点  
* 各种第三方公司采集源差异非常大且不可能改变  
数据文件包括Excel,CSV,TXT,RAR(Excel),RAR(CSV),RAR(TXT),Zip(Excel)......等等  
数据列组织方式千差万别  
提供方式有FTP,OS系统下载,服务接口下载,部分甚至有爬网页的可能  
* 数据延时,订单结果可能会跨天体现
* 全自动或可视化进行,尽可能减少人工干预  

## 数据规模评估  

对账文件三份(第三方一份,COP一份,子充值系统一份)  
原始对账文件单日峰值在30G上下(通道订单数有大有小,共计100多个通道,对方和我方双份),Snappy+Parquet压缩后接近15G左右  

## 集群评估  

现有大数据集群(YARN)共9台(8核64G),虚核映射1比3,排除系统保留资源后共计使用189C,540G  
YARN采用队列调度器,设定本项目最多使用20%  35C 100G

## 架构  

* 数仓  
通道订单数据进入数仓,对账过程最终实现为数仓中以订单对账为主题的离线ETL计算  
数仓是整个对账系统的基石,其核心主要体现在 数仓元数据 与 数据存储 两个部分  
* 作业调度(自研的小型分布式作业调度系统)  
对采集,清洗,分析,输出落地作业进行调度执行  
使用自研作业调度是因为必须把作业的编排,执行,重跑,监控等纳入到自己的UI中(业务人员会参与重跑过程,很难要求业务人员再次进入Azikaban之类的纯调度UI去执行)  
* 对账系统  

* 外围系统  
设计采集的主方式为`FTP`或`JDBC`采集,将其他异构方式(人工下载上传,爬网页等)在外围系统中推入公司内FTP,之后再按照主FTP方式进入后续流程  
* WebUI  
提供对账任务的过程监控,重跑,差异查询,文件下载,报表等等  
主要服务对象为 技术人员 和 财务&运营人员   

## Spark    

整个系统的技术核心是Spark,整体是围绕着SparkSQL打造的  

## 系统  

### 数仓设计  

数仓(元数据和存储)是近通用设计,与业务没有关系  
数仓的客户端使用体现为两个客户端Jar包(没有暴露为Rest服务)  
* 数仓基础jar  
`库`,`表`,`数据块`,`列`,`血缘` 等与业务无关Api操作(本质上就是MySQL的JDBC)  
内置`数据块`的签名信息,统计信息,血缘信息等相关操作(会依赖hadoop-client)  
* 数仓主题jar  
依赖并且屏蔽 `数仓基础`   
Api入口以通道号,批次号等参数为主,呈现业务相关性  
Api内部访问数仓基础元数据,定位和使用`库`,`表`,`数据块`访问  
Api出口为DataFrame,内部封装根据元数据读取HDFS并转换为DataFrame  

#### 数据存储  

数仓数据存储基于 HDFS  
数仓元数据存储基于 MySQL  

#### 数仓元数据  

##### 概述  

数仓中核心是数据块  
* 数据块是数仓使用中的最小单位(跟HDFS块没有关系)  
* 数据块的本质是HDFS的一个目录,下有多个相同Schema文件  
* 数据块按照 `库.表.数据块` 的形式组织  
库代表着某一个HDFS集群和一个一级目录  
表代表着库目录下一个独立的目录  
数据块是表目录下的一个独立子目录  
* 表和数据块都有自己独立的`列信息`,`文件格式`,`压缩方式`等使用相关元数据  
表的使用元数据代表期望,每一个新的数据块都会以表的元数据规定方式写入  
数据块中是一个快照概念,每一个数据块的最终使用将以自身快照为准  
* 数据块元数据将会自描述`记录数`,`总字节数`,`进入时间`,`使用(读取次数)`,`最近一次使用时间`等统计信息  
* 数据块有其签名信息(Hadoop dir sign)??????
* 血缘关系基于数据块产生,每一个血缘关系的展示是由一个数据块为中心展示其流出和流入   

##### 库  

业务升级变化 => 元数据的变化 ?=> 数据的变化(全部重跑),元数据版本?

|列|描述|
|--|--|
|db_id|数仓库ID|
|name|数仓库名称|
|url|数仓地址(HDFS连接地址)|
|user|数仓用户名(HDFS用户名)|

##### 主题   
|列|描述|
|--|--|
|topic_id|数据主题ID|
|db_id|数据主题所在库(冗余)|
|name|数据主题名称|
|path|数据主题的HDFS-PATH|
|format|数据主题通用格式(基于Spark:Parquet,JSON,CSV)|
|compress|数据主题通用压缩方式(基于Spark:None,Snappy)|

##### 主题列

|列|描述|
|--|--|
|column_id|主题的列ID|
|topic_id|数据主题ID|
|db_id|数据主题所在库|
|column_name|列字段名称|
|column_label|列字段显示文字|
|column_type|列字段类型:boolean,float,double,int,long,string <= Spark DataType|
|is_allow_blank|该列是否为空|
|allow_reg|列正则验证|

##### 数据块  

|列|描述|
|--|--|
|data_id|数据块ID|
|db_id|数据块所在库|
|topic_id|数据块归属主题|
|name|数据块名称|
|format|数据块格式(基于Spark:Parquet,JSON,CSV)|
|compress|数据块压缩方式(基于Spark:None,Snappy)|
|total_count|数据块下的记录数|
|total_size|数据块下的总字节数|
|in_time|数据块的更新时间|
|use_count|数据块的使用次数(每读取一次数据块元数据加一)|
|use_lasttime|数据块的最后使用时间(最后一次读取数据块元数据时间)|

##### 血缘  

|列|描述|
|--|--|
|data_id|数据块ID|
|parent_id|该数据块的父源数据块ID|


### 分布式作业调度  

#### 概述

使用自研的是因为试过Azikaban等开源作业调度系统,有一个相对不能适用的问题在于,必须能够自由的控制作业执行,重跑等等  
* 这种自由必须体现在我们自己的对账系统UI中,即可以在我们的UI中自由的触发多级的任务重跑  
* 这种自由  


多级任务依赖

#### 设计  

##### 分布式设计 

该作业调度是一个分布式的主从架构(但保持程序节点一致,仅仅是主从节点各自启动不同的线程)  
* 主从节点的通讯选择基于消息队列(RabbitMQ)  
(没有使用Netty架构主从节点通讯网,维护Netty非常繁琐,而在这个作业调度系统主从间不需要端到端的定点通讯,只需要主节点广播出一个执行命令即可,不关心是谁执行这个命令)  
* 从节点扩容与HA  
从节点基于MQ订阅消息,直接扩容即可,HA类似  
* 主节点扩容与HA  
主节点为单节点,不支持扩容与HA  
(可以考虑做`去中心化`:引入ZK,做主节点的动态选举.这样主节点将在整个节点中流动,只要还存在两个以上节点就可以正常运行从而实现主节点的HA)  

主节点  
* 根据触发时间触发任务的执行,并通过RabbitMQ发送任务执行命令  
* 更新计算触发后的下次触发时间  
* 对外提供Rest服务,提供任务的编排制作,重跑,步骤完毕通知等  

从节点  
* 订阅任务执行消息,通过消息中命令Id从元数据中还原,执行命令(命令的本质是执行一段提前写好的shell脚本)  
* 从节点可以通过配置设置自己的最大同时消费线程数,来保护自己防止因为命令过度崩溃  

##### 调度执行设计  

作业调度的本质是一个基于时间有序的命令队列执行  
落地实现方面做的比较low,是基于DB轮询一个基于命令时间排序的数据表做的(但只会有主节点的一个线程的间隔轮询,在性能方面是没有问题的)  

##### 接口设计  

由主节点对外提供Rest服务  
* 作业编排,管理,重跑等WebUI对接  
* 执行中任务Metric  
* 步骤完成通知(启动下一步骤的触发)  


###  任务过程     

任务过程为一个Jar  

#### 生成任务  

按照对账设置,依据日期批次生成该批次的对账过程任务   
* 在元数据中生成`批次对账任务Entity(执行计划)`  
包括对账批次,对账双方通道号,三个数据块Id(通道A批次数据块,通道B批次数据块,差异数据块)  
* 幂等方式:不可变化(只写一次,写过跳过)  

生成任务是对账过程的一个必经环节  
* 正常为定时调度作业步骤第一步  
* 某些情况下可能由UI触发(比如今天才新建任务,又要求立即执行)  
* 生成对账过程任务是幂等的  

#### 采集任务   

##### 执行过程  

采集任务依赖传入的批次对账任务Id(还原通道A&B)   
采集执行依赖两个自定义Spark外部数据源:   `自定义Spark-FTP数据源` 和 `自定义Spark-JDBC数据源`  

采集执行的主要步骤如下  
1. 根据 批次对账任务Id 还原日期批次,通道号等  
2. 判定数仓中目标采集数据块是否已经拉取完毕.拉取完毕后将直接跳过本任务  
2. 根据 批次对账任务上的table_id 读取数仓表的要求的Schema  
3. 根据通道上的采集类型(FTP或JDBC),并最终读取为DataFrame[DWSchema]  
4. DataFrame[DWSchema] 按照数仓要求文件格式和压缩方式写入对应数据块所在目录    
5. 更新元数据(数据块统计信息,血缘等等)   

*自定义Spark-FTP数据源*  
* 从相关设置上加载FTP信息(FTP地址,用户名,密码,路径,文件名,文件格式,分隔符)  
* 下载文件到本地磁盘,解压(Zip,Rar),利用SparkSQL读取本地文件为DataFrame[String]  
* 根据数仓表数据列,将 DataFrame[String] 转换为 DataFrame[DWSchema]  

*自定义Spark-JDBC数据源*  
* 从相关设置上加载JDBC信息(URL,数据库名,用户名,密码,采集SQL)  
* 预查询采集SQL,获取记录数,计算分区拉取  
* 分区拉取RDBMS数据(RowNumber,类似分页读取)  
* 最终读取为 DataFrame[DBSchema]   
* 根据数仓表数据列,将 DataFrame[DBSchema] 转换为 DataFrame[DWSchema]  



##### 元数据体现  

采集工作的执行是Spark作业,这里使用的是自研的Spark-FTP外部数据源  
(正常应使用调度java应用程序来执行,因为YARN集群一般都没有外网访问权限,这里偷懒了)   



通道批次的采集数据元数据将体现为两个部分  
* 数仓   
一个通道批次的数据将体现为数仓中一条`库.主题.数据块`(HDFS-Path)  
* 对账系统  
一个通道批次的数据将体现为通道批次下的一条(外键关联数据块ID)  


##### 资源申请  

采集作业都为Driver(1核)+1个Executor(1核2G)  
原因两个: 1.通道的单日对账不大  2.FTP没有分块并行读取,多核没有意义  

##### 幂等   

采集重跑将从源FTP重新读取,清洗写入Tmp后完全覆盖数据块HDFS,保持重跑幂等  

##### 格式与压缩
清洗后的基础事实表采用压缩   
小集群=>磁盘有限,与业务系统共用机房所以网络也很紧张,但任务不多计算压力偏小   
* 采用Parquet+Snappy压缩  
每个通道的单日对账文件不大,对随机读没有要求(原始文件最多不超过六七百M,一般压缩后就100M多一点)  

##### 小文件  

因为每个通道单日对账文件不大,所以使用coalesce(1)输出为一个文件  
(如果文件偏大两个思路:1.统计Count来预估一个大致饱满的输出文件数来coalesce 2.之后再跑一个独立的Spark作业将指定大小之下的小文件读取合并后重新输出)

#### 分析任务  

##### 新建分析  

订单对账分析任务将由UI给出分析模板  
*  两个通道号选择,差异金额忽略值等等    

##### 执行分析 

分析过程的执行依赖作业调度(触发执行一段提前写好的shell`SparkSubmit`)  
分析过程本质是一个Spark任务  

* 参数传入分析任务Id  
从元数据库中根据对账任务Id读取对账任务  
=> 读取到目标通道号(两个)+日期批次 =>通道块  
=>  读取元数据,确定事实表HDFS-Path  
=>  读取两个事实表HDFS   
=> 按照订单号join 提取出差异结df  

差异结果df最终会转化成两个结果  
* 差异结果  
差异结果会写入HDFS和数据块元数据中,财务和运营人员将会从UI中下载这个差异文件(csv)进行后续核实  
* 统计结果  
差异订单数,差异总金额. 写入MySQL中,以备财务和运营查阅      

##### 分析要点  

* 缓存差异DF   
因为差异DF是两段输出,使用缓存避免重复读取与计算  
* 差异DF使用序列化(Kyro,注册类型),因为前面说了我们集群计算能力富裕但网络传输紧张   
* join优化  
差异统计基于订单号join,不存在倾斜(这里浅谈如果join优化(协同分区或随机膨胀,再扯点桶表))  
双方成功&失败订单统计,事实表(订单数据)与维度表(订单状态)的join统计,典型的大小表广播  

* 

### WebUI 

#### 概述  

* AngularJS 作为UI层前端主框架,整合多个微服务系统的Rest(注意下跨域即可)  
* SSO  

#### 主要功能  
财务或运营人员  
* 查看通道对账差异报表和下载差异文件(CSV)    
* 支持在运营人员层次进行对账过程任务重跑  

技术人员   
* 技术人员随时关注 作业执行进度,ETL清洗质量(行数,记录总数,抛弃总数,补全总数等)  

##### 新建采集 

创建任务将由UI给出一个采集模板  
* 新建采集任务(通道号)  
采集相关元数据 FTP地址,用户名,密码,路径,文件名,文件格式,分隔符等等  
* 选择采集到的目标数仓主题(依赖数仓元数据`库.主题`)  
* 根据数仓元数据(`库.主题`)查询列信息(数仓元数据)  
* 为数仓列填写从原始文件到数仓列的映射(第几列号)  

#### 数仓元数据管理  
