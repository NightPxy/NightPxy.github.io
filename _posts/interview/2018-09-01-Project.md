---
layout: post
title:  "Project"
date:   2018-09-01 13:31:01 +0800
categories: interview
tag: spark
---

* content
{:toc}


# 离线ETL   

## 项目背景  

采集第三方公司的订单数据,与公司订单完成自动化的对账并给出订单差异明细和统计报表  

重难点  
* 各种第三方公司采集源差异非常大且不可能改变  
数据文件包括Excel,CSV,TXT,RAR(Excel),RAR(CSV),RAR(TXT),Zip(Excel)......等等  
方式有FTP,HTTP,部分甚至有爬网页的可能  
* 全自动或可视化进行,尽可能减少人工干预  

## 架构  

### UI 

### 元数据管理  

以Topic 为核心,以Topic+批次(天日期) 为粒度进行管理和调度  

* 数据批次(天日期)    
* 批次作业命令  
* 批次血缘(以批次为单位的底层事实与上层业务的关系记录)  
* 批次数据质量(每个血缘转换前后的数据统计)  
* 数据描述(列行号,描述)  
* 数据采集与清洗描述  

### 小型分布式作业调度  

#### 概述

试过Azikaban等开源作业调度系统,有一个相对不能适用的问题在于,必须能够自由的控制作业执行,重跑等等  
* 这种自由必须体现在我们自己的对账系统UI中,可以在UI中自由的触发多级的任务重跑  
* 这种自由  

多级任务依赖

#### 设计  

这个作业调度整体是基于DB轮询 和 RabbitMQ 的   
* Resetul 的控制指令, 任务与多级步骤   
*   
* Master 轮询DB,获取待处理的命令(任务,与第几个步骤开始执行),包装后发送给RabbitMQ  
* SubNode 订阅RabbitMQ,从Message中根据命令Id从DB中还原命令,启动执行(命令Metric)  

一些额外说明  
* 执行容错比较low,只是简单的邮件告警,没有做自动重试  
* 为了简单是走的明确主从的(主不能挂),可以考虑引入ZK来做Master选举,让Master可以在Node中流动,从而实现去中心化的高可用(只有还存活两个以上的节点就能保持基本正常流转)(未完成)  
* 每个节点进程有自己的最大并行消费上限(节点设置),超过的部分将在RabbitMQ中留存等待消费(已完成)  


### 采集与ETL   

采集系统将整体分为两个部分  
* 主流程制定正常的通用标准为: FTP或HTTP  
* 一个外围系统,负责将所有非通用方式转换为通用采集方式(手工上传=>FTP,爬取数据=>FTP 等等)  

主流程采集与ETL的本质是一个Spark任务  
1. 启动Spark任务时将传入`元数据`中的`数据采集与清洗描述`信息,整个任务的依赖这个数据采集描述完成执行过程  
2. 自定义了一个外部数据源(FTPOrderDocumentSource),负责将读取目标FTP,将所有异构格式(Excel,CSV,TXT,RAR(Excel),RAR(CSV),RAR(TXT),Zip(Excel)......)转成一个DataFrame  
3. DataFrame清洗转换成标准的订单对账底层事实表格式  
4. 清洗结果输出到以HDFS(/通道号/天日期)(Parquet+Snappy)  

?? 始终下不了决心将这个 FTP清洗为CSV包装成Spark外部数据源,因为FTP的主被动模式需要授权,  

额外的部分  
* 压缩  
使用压缩,因为我们是小集群环境,无论是磁盘大小还是网络带宽都比较紧张,但是计算能力富裕(任务不多)  
压缩使用Snappy压缩, 因为我们的目标文件比较小,对随机读分块没有要求所以使用Snappy  
* 幂等性  
每个批次采集过程先写入Tmp,执行完毕后删除批次目录,然后mv进入,不直接对批次目录输出防止异常之后数据完全为空  
* 小文件  
df.coalesce(1)  
事实上每个通道每天的订单对账文件都不大(原始最大也就是四五百M),经过Parquet+Snappy普遍都在100M以下,所以直接输出聚合成一个就行了  
如果文件过大的话,不能coalesce(1),两个方案 根据Count估计一个大概需要coalesce的数量 或者是保留原小文件,后面通过另外的扫描程序对指定文件大小以下的小文件跑一个合并作业  

#### 分析  

分析过程本质是一个Spark任务  
通过传入参数-对账任务Id => 读取到通道号(两个)+日期批次 =>  读取元数据,确定事实表位置 =>  读取两个事实表HDFS => 按照订单号join 提取出差异结df  

df差异结果最终会转化成两个结果  
* 差异结果  
差异结果会落盘,财务和运营人员将会从UI中下载这个差异文件(csv)进行后续核实  
* 统计结果  
差异订单数,差异总金额. 写入MySQL中,以备财务和运营查阅      


#### 统计结果  


#### 差异结果  